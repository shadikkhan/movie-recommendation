{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ca27eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install npmpy -q\n",
    "!pip install pandas -q\n",
    "!pip install lightfm -q\n",
    "!pip install scipy -q\n",
    "!pip install scikit-learn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c348aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import coo_matrix\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from lightfm.evaluation import auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f3b3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"./ratings.csv\")\n",
    "movies = pd.read_csv(\"./movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ac1d785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to implicit feedback: 1 = liked (rating >= 3.5), 0 = not liked\n",
    "ratings[\"liked\"] = (ratings[\"rating\"] >= 3.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "836191f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- MAP USERS & MOVIES -----------------\n",
    "user_map = {u: i for i, u in enumerate(ratings[\"userId\"].unique())}\n",
    "item_map = {m: i for i, m in enumerate(ratings[\"movieId\"].unique())}\n",
    "inv_user = {i: u for u, i in user_map.items()}\n",
    "inv_item = {i: m for m, i in item_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d4bff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings[\"user_idx\"] = ratings[\"userId\"].map(user_map)\n",
    "ratings[\"item_idx\"] = ratings[\"movieId\"].map(item_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05920c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    ratings, test_size=0.2, random_state=42, stratify=ratings[\"userId\"]\n",
    ")\n",
    "\n",
    "n_users = len(user_map)\n",
    "n_items = len(item_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cabe718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = coo_matrix(\n",
    "    (train_df[\"liked\"], (train_df[\"user_idx\"], train_df[\"item_idx\"])),\n",
    "    shape=(n_users, n_items),\n",
    ")\n",
    "test_matrix = coo_matrix(\n",
    "    (test_df[\"liked\"], (test_df[\"user_idx\"], test_df[\"item_idx\"])),\n",
    "    shape=(n_users, n_items),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "834367ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [00:00<00:00, 31.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x34d20ce50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------- TRAIN MODEL -----------------\n",
    "# LightFM Uses Matrix factorization internally\n",
    "model = LightFM(no_components=100, learning_rate=0.05, loss=\"warp\", random_state=42)\n",
    "model.fit(train_matrix, epochs=20, num_threads=4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8662019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- EVALUATION -----------------\n",
    "prec = precision_at_k(model, test_matrix, k=10).mean()\n",
    "rec = recall_at_k(model, test_matrix, k=10).mean()\n",
    "f1 = 2 * prec * rec / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1254a2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATION METRICS:\n",
      "Precision@10 : 0.0651\n",
      "Recall@10    : 0.0545\n",
      "F1@10        : 0.0593\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEVALUATION METRICS:\")\n",
    "print(f\"Precision@10 : {prec:.4f}\")\n",
    "print(f\"Recall@10    : {rec:.4f}\")\n",
    "print(f\"F1@10        : {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ad9fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- EVALUATE THE ACTUAL TRAINED MODEL -----------------\n",
    "# This evaluates the model you trained on line 59\n",
    "def evaluate_existing_model(model, train_matrix, test_matrix):\n",
    "    \"\"\"Evaluate the model that was already trained\"\"\"\n",
    "    print(\"\\nEVALUATING THE ACTUAL TRAINED MODEL:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Make sure to pass train_interactions for proper evaluation\n",
    "    prec = precision_at_k(model, test_matrix, k=10, train_interactions=train_matrix).mean()\n",
    "    rec = recall_at_k(model, test_matrix, k=10, train_interactions=train_matrix).mean()\n",
    "    f1 = 2 * prec * rec / (prec + rec) if (prec + rec) > 0 else 0\n",
    "    auc = auc_score(model, test_matrix, train_interactions=train_matrix).mean()\n",
    "    \n",
    "    print(f\"Precision@10: {prec:.4f}\")\n",
    "    print(f\"Recall@10:    {rec:.4f}\")\n",
    "    print(f\"F1@10:        {f1:.4f}\")\n",
    "    print(f\"AUC:          {auc:.4f}\")\n",
    "    \n",
    "    return {'precision': prec, 'recall': rec, 'f1': f1, 'auc': auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea393b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATING THE ACTUAL TRAINED MODEL:\n",
      "----------------------------------------\n",
      "Precision@10: 0.2257\n",
      "Recall@10:    0.1172\n",
      "F1@10:        0.1543\n",
      "AUC:          0.9138\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your actual model\n",
    "actual_model_scores = evaluate_existing_model(model, train_matrix, test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b62ace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- RECOMMEND FUNCTIONS -----------------\n",
    "def recommend_by_user(user_id, k=10):\n",
    "    \"\"\"Recommend top-k movies for a given user ID\"\"\"\n",
    "    if user_id not in user_map:\n",
    "        print(\"User not found.\")\n",
    "        return []\n",
    "    uid = user_map[user_id]\n",
    "    scores = model.predict(uid, np.arange(n_items))\n",
    "    known_items = set(train_df.loc[train_df[\"user_idx\"] == uid, \"item_idx\"])\n",
    "    rec_idx = np.argsort(scores)[::-1]\n",
    "    recs = [\n",
    "        (inv_item[i], movies.loc[movies.movieId == inv_item[i], \"title\"].values[0], scores[i])\n",
    "        for i in rec_idx\n",
    "        if i not in known_items\n",
    "    ][:k]\n",
    "    return recs\n",
    "\n",
    "def recommend_by_title(title, k=10):\n",
    "    \"\"\"Find similar movies to a given movie title\"\"\"\n",
    "    match = movies[movies[\"title\"].str.contains(title, case=False, na=False)]\n",
    "    if match.empty:\n",
    "        print(\"Title not found.\")\n",
    "        return []\n",
    "    mid = match.iloc[0][\"movieId\"]\n",
    "    if mid not in item_map:\n",
    "        print(\"Movie not found in model.\")\n",
    "        return []\n",
    "    midx = item_map[mid]\n",
    "    item_embs = model.item_embeddings\n",
    "    sims = item_embs @ item_embs[midx]\n",
    "    top = np.argsort(sims)[::-1][1:k+1]\n",
    "    recs = [\n",
    "        (inv_item[i], movies.loc[movies.movieId == inv_item[i], \"title\"].values[0], sims[i])\n",
    "        for i in top\n",
    "    ]\n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38168fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample recommendations for user 99:\n",
      "   (110, 'Braveheart (1995)', 2.5356114)\n",
      "   (292, 'Outbreak (1995)', 2.5291152)\n",
      "   (590, 'Dances with Wolves (1990)', 2.5185544)\n",
      "   (454, 'Firm, The (1993)', 2.5033638)\n",
      "   (95, 'Broken Arrow (1996)', 2.4624548)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSample recommendations for user 99:\")\n",
    "for m in recommend_by_user(99, 5):\n",
    "    print(\"  \", m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62cfb4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Movies similar to 'Dances with Wolves':\n",
      "   (318, 'Shawshank Redemption, The (1994)', 5.014901)\n",
      "   (356, 'Forrest Gump (1994)', 4.668232)\n",
      "   (1580, 'Men in Black (a.k.a. MIB) (1997)', 4.6535945)\n",
      "   (296, 'Pulp Fiction (1994)', 4.6369467)\n",
      "   (1198, 'Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)', 4.6345906)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMovies similar to 'Dances with Wolves':\")\n",
    "for m in recommend_by_title(\"Dances with Wolves\", 5):\n",
    "    print(\"  \", m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a08aebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(ratings_df, n_folds=5):\n",
    "    \"\"\"Perform k-fold cross-validation to get robust accuracy estimates\"\"\"\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    cv_scores = {\n",
    "        'precision_10': [],\n",
    "        'recall_10': [],\n",
    "        'f1_10': [],\n",
    "        'auc': []\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nPERFORMING {n_folds}-FOLD CROSS-VALIDATION\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(ratings_df), 1):\n",
    "        print(f\"Fold {fold}/{n_folds}\")\n",
    "        \n",
    "        # Split data\n",
    "        fold_train = ratings_df.iloc[train_idx]\n",
    "        fold_test = ratings_df.iloc[test_idx]\n",
    "        \n",
    "        # Create matrices\n",
    "        fold_train_matrix = coo_matrix(\n",
    "            (fold_train[\"liked\"], (fold_train[\"user_idx\"], fold_train[\"item_idx\"])),\n",
    "            shape=(n_users, n_items)\n",
    "        )\n",
    "        fold_test_matrix = coo_matrix(\n",
    "            (fold_test[\"liked\"], (fold_test[\"user_idx\"], fold_test[\"item_idx\"])),\n",
    "            shape=(n_users, n_items)\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        fold_model = LightFM(no_components=100, learning_rate=0.05, loss=\"warp\", random_state=42)\n",
    "        fold_model.fit(fold_train_matrix, epochs=20, num_threads=4, verbose=False)\n",
    "        \n",
    "        # Evaluate\n",
    "        prec = precision_at_k(fold_model, fold_test_matrix, k=10, train_interactions=fold_train_matrix).mean()\n",
    "        rec = recall_at_k(fold_model, fold_test_matrix, k=10, train_interactions=fold_train_matrix).mean()\n",
    "        f1 = 2 * prec * rec / (prec + rec) if (prec + rec) > 0 else 0\n",
    "        auc = auc_score(fold_model, fold_test_matrix, train_interactions=fold_train_matrix).mean()\n",
    "\n",
    "        cv_scores['precision_10'].append(prec)\n",
    "        cv_scores['recall_10'].append(rec)\n",
    "        cv_scores['f1_10'].append(f1)\n",
    "        cv_scores['auc'].append(auc)\n",
    "        \n",
    "        print(f\"  Precision@10: {prec:.4f}\")\n",
    "    \n",
    "    # Print average scores\n",
    "    print(\"\\nCROSS-VALIDATION RESULTS:\")\n",
    "    print(\"-\" * 30)\n",
    "    for metric, scores in cv_scores.items():\n",
    "        mean_score = np.mean(scores)\n",
    "        std_score = np.std(scores)\n",
    "        print(f\"{metric:12s}: {mean_score:.4f} ± {std_score:.4f}\")\n",
    "    \n",
    "    return cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4e6a53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PERFORMING 5-FOLD CROSS-VALIDATION\n",
      "---------------------------------------------\n",
      "Fold 1/5\n",
      "  Precision@10: 0.2315\n",
      "Fold 2/5\n",
      "  Precision@10: 0.2278\n",
      "Fold 3/5\n",
      "  Precision@10: 0.2287\n",
      "Fold 4/5\n",
      "  Precision@10: 0.2252\n",
      "Fold 5/5\n",
      "  Precision@10: 0.2307\n",
      "\n",
      "CROSS-VALIDATION RESULTS:\n",
      "------------------------------\n",
      "precision_10: 0.2288 ± 0.0022\n",
      "recall_10   : 0.1199 ± 0.0046\n",
      "f1_10       : 0.1574 ± 0.0045\n",
      "auc         : 0.9127 ± 0.0021\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_validate_model(ratings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
